{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "___\n",
    "#### Description:\n",
    "Sentiment analysis is the task of analyzing text and classifying it as either a positive or negative sentiment. In this case, the dataset consists of movie reviews where a positive review has a sentiment rating of '1' and a negative review has a sentiment rating of '0'. There are many ways to go about performing sentiment analysis, but in this notebook I will use a many-to-one recurrent neural network because they perform well on sequential data. \n",
    "___\n",
    "#### Dataset:\n",
    "The original dataset comes from http://ai.stanford.edu/~amaas/data/sentiment/ and contains 25,000 training examples, but I used a reuploaded version from https://www.kaggle.com/c/word2vec-nlp-tutorial/data. \n",
    "\n",
    "Note: \n",
    "Keras actually provides the dataset already preprocessed under keras.datasets.imdb, but in this notebook I will preprocess the dataset from scratch.\n",
    "___\n",
    "#### Reference:\n",
    "My intuition behind RNN's and sentiment analysis comes from taking Andrew Ng's Deep Learning course. \n",
    "\n",
    "These following resources were also used as a helpful guide:\n",
    "\n",
    "https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/\n",
    "\n",
    "https://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_table('labeledTrainData.tsv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into reviews and sentiments\n",
    "reviews = df['review']\n",
    "sentiments = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This has to be one of the most sincere and touching boy-meets-girl movies ever made. While \\\\Rebel Without a Cause\\\\\" and \\\\\"Say Anything\\\\\" deliver nice portrayals, this movies strips down useless subplots and Hollywood divergences. This movie focuses purely on watching the budding of a beautiful romance. You never doubt for a second that the film will lead towards the romantic pairing of these two people. You almost immediately sense the synergy and the chemistry between Jesse and Celine, and it is simply pure joy to watch them find it. This movie is mostly all dialogue -based. But, every conversation between these too is greatly intriguing. What makes this pairing so romantic is how real it is. How in all that conversation, while often having no real bearing on anything critical, you can sense the nuances as these two become more fond and trusting of each other. This is exactly they way you would dream that you meet that special someone. And what makes it so true is that it is not even too fantastic to believe. This could be what would happen if you had been confident enough to strike up a conversation with that person you noticed somewhere random. And what puts the icing on this film is the magnificent backdrop of Vienna in which this film takes place. It just adds to the feeling of romantic nirvana that the film suggests. And no matter how many times I watch this film, I don\\'t think I will ever tire of that.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a review to get an idea of how to preprocess\n",
    "reviews[np.random.randint(len(reviews))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean a review\n",
    "def clean_review(review):\n",
    "    review = re.sub('<[^<>]+>', ' ', review) # Remove html formatting\n",
    "    review = review.replace('\\x96', ' ') # Remove weird box symbol apparent in some examples\n",
    "    review = review.lower() # Make letters lowercase\n",
    "    words = review.split() # Split review into words for further cleaning\n",
    "    words = [re.sub('[^a-z]', '', word) for word in words] # Remove non-alphabetical characters\n",
    "    review = ' '.join(words) # Put words back together to form clean review\n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean every review\n",
    "clean_reviews = [clean_review(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " The film was made in 1942 and with World War 11 around, the movie industry decided to capitalize on the fact that spies were around.<br /><br />The film is fun to watch due to the fabulous dancing of Eleanor Powell. The late Miss Powell was certainly a great hoofer in every sense of the word. She is again paired with a very young looking Red Skelton here. The two of them also starred in \\I Dood It.\\\"<br /><br />Moroni Olsen, who 3 years later, was superb as the interrogating police officer in \\\"Mildred Pierce\\\" again appears as an officer asking Powell to deliver an item. Trouble is that Olsen and his rogues are really the Japanese spies.<br /><br />Bert Lahr is his usual brilliant self here and he gets ample support from Virginia O'Brien.\"\n",
      "\n",
      "Cleaned:\n",
      " the film was made in  and with world war  around the movie industry decided to capitalize on the fact that spies were around the film is fun to watch due to the fabulous dancing of eleanor powell the late miss powell was certainly a great hoofer in every sense of the word she is again paired with a very young looking red skelton here the two of them also starred in i dood it moroni olsen who  years later was superb as the interrogating police officer in mildred pierce again appears as an officer asking powell to deliver an item trouble is that olsen and his rogues are really the japanese spies bert lahr is his usual brilliant self here and he gets ample support from virginia obrien\n"
     ]
    }
   ],
   "source": [
    "# Compare an original to a cleaned review\n",
    "index = np.random.randint(len(reviews))\n",
    "\n",
    "print('Original:\\n', reviews[index])\n",
    "print('\\nCleaned:\\n', clean_review(reviews[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each review to a vector of integers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(clean_reviews)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(clean_reviews) # list of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 18, 12, 89, 7, 2, 15, 184, 328, 183, 1, 16, 1538, 833, 5, 19, 1, 186, 11, 64, 183, 1, 18, 6, 243, 5, 102, 663, 5, 1, 2664, 1098, 4, 2538, 1, 523, 701, 2538, 12, 421, 3, 83, 7, 169, 272, 4, 1, 687, 53, 6, 171, 15, 3, 51, 181, 282, 794, 127, 1, 103, 4, 92, 76, 2753, 7, 9, 8, 35, 146, 292, 12, 878, 13, 1, 549, 1848, 7, 3910, 4954, 171, 712, 13, 32, 1848, 2141, 2538, 5, 1567, 32, 1075, 6, 11, 2, 23, 22, 61, 1, 850, 6, 23, 621, 514, 1307, 127, 2, 26, 202, 1358, 34, 4416]\n"
     ]
    }
   ],
   "source": [
    "# Display a review in its new representation\n",
    "print(sequences[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 500\n"
     ]
    }
   ],
   "source": [
    "# Choose length of sequence (input)\n",
    "maxlen = 500\n",
    "print('Max length:', maxlen) \n",
    "\n",
    "# The actual longest review has a sequence length of 1311, but \n",
    "# this will make training slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  108639\n"
     ]
    }
   ],
   "source": [
    "# Vocab size\n",
    "vocab_size = len(tokenizer.word_index) + 1 # including 0th index\n",
    "print('Vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to max length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=maxlen, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (25000, 500)\n",
      "y shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Get the inputs and outputs ready for training\n",
    "X = sequences\n",
    "y = np.array(sentiments)\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           3476448   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,529,749\n",
      "Trainable params: 3,529,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build a RNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=X.shape[1]),\n",
    "    LSTM(100, dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/15\n",
      "20000/20000 [==============================] - 1348s 67ms/step - loss: 0.4970 - acc: 0.7464 - val_loss: 0.3626 - val_acc: 0.8428\n",
      "Epoch 2/15\n",
      "20000/20000 [==============================] - 1289s 64ms/step - loss: 0.3107 - acc: 0.8759 - val_loss: 0.3206 - val_acc: 0.8688\n",
      "Epoch 3/15\n",
      "20000/20000 [==============================] - 1182s 59ms/step - loss: 0.3172 - acc: 0.8667 - val_loss: 0.3384 - val_acc: 0.8650\n",
      "Epoch 4/15\n",
      "20000/20000 [==============================] - 1452s 73ms/step - loss: 0.2291 - acc: 0.9113 - val_loss: 0.3379 - val_acc: 0.8704\n",
      "Epoch 5/15\n",
      "20000/20000 [==============================] - 1419s 71ms/step - loss: 0.2346 - acc: 0.9073 - val_loss: 0.4099 - val_acc: 0.8422\n",
      "Epoch 6/15\n",
      "20000/20000 [==============================] - 1592s 80ms/step - loss: 0.1905 - acc: 0.9280 - val_loss: 0.3943 - val_acc: 0.8654\n",
      "Epoch 7/15\n",
      "20000/20000 [==============================] - 1356s 68ms/step - loss: 0.1569 - acc: 0.9414 - val_loss: 0.5625 - val_acc: 0.8330\n",
      "Epoch 8/15\n",
      "20000/20000 [==============================] - 1014s 51ms/step - loss: 0.1397 - acc: 0.9480 - val_loss: 0.4374 - val_acc: 0.8646\n",
      "Epoch 9/15\n",
      "20000/20000 [==============================] - 1020s 51ms/step - loss: 0.1140 - acc: 0.9596 - val_loss: 0.4819 - val_acc: 0.8566\n",
      "Epoch 10/15\n",
      "20000/20000 [==============================] - 1018s 51ms/step - loss: 0.1140 - acc: 0.9602 - val_loss: 0.5262 - val_acc: 0.8510\n",
      "Epoch 11/15\n",
      "20000/20000 [==============================] - 1016s 51ms/step - loss: 0.1112 - acc: 0.9619 - val_loss: 0.5212 - val_acc: 0.8308\n",
      "Epoch 12/15\n",
      "20000/20000 [==============================] - 1021s 51ms/step - loss: 0.1128 - acc: 0.9596 - val_loss: 0.5236 - val_acc: 0.8334\n",
      "Epoch 13/15\n",
      "20000/20000 [==============================] - 1023s 51ms/step - loss: 0.0899 - acc: 0.9688 - val_loss: 0.5650 - val_acc: 0.8430\n",
      "Epoch 14/15\n",
      "20000/20000 [==============================] - 1023s 51ms/step - loss: 0.0695 - acc: 0.9768 - val_loss: 0.6098 - val_acc: 0.8526\n",
      "Epoch 15/15\n",
      "20000/20000 [==============================] - 1026s 51ms/step - loss: 0.0724 - acc: 0.9759 - val_loss: 0.6870 - val_acc: 0.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176d4289710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit the model to X and y\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Checkpoint weights after every epoch (optional)\n",
    "checkpoint = ModelCheckpoint('weights-{epoch:02d}-{val_acc:.2f}.hdf5')\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit\n",
    "model.fit(X, y, epochs=15, validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the summary for it\n",
    "model.save('sentiment_analysis_movies.h5')\n",
    "\n",
    "with open('sentiment_analysis_movies.txt', 'w+') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to new examples\n",
    "example = \"This movie was complete trash directed by someone who hasn't even read the script. \\\n",
    "Speaking of the script, it was full of holes and felt that it was written within a week. This \\\n",
    "movie was beyond disappointing. Save yourself 2 hours and avoid this movie at all costs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the example\n",
    "example = clean_review(example)\n",
    "example = tokenizer.texts_to_sequences([example])\n",
    "example = pad_sequences(example, maxlen=maxlen, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1450485e-06]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction\n",
    "model.predict(example)\n",
    "# Consider values > 0.5 to be positive reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
